import argparseimport osimport numpy as npimport mathimport torchvision.transforms as transformsfrom torchvision.utils import save_imagefrom torch.utils.data import DataLoaderfrom torchvision import datasetsfrom torch.autograd import Variableimport torch.nn as nnimport torch.nn.functional as Fimport torchimport wandbfrom utils.dataloader import CelebADatasetfrom utils.gans import Generator,Discriminatorcuda = True if torch.cuda.is_available() else Falsetransform = transforms.Compose([transforms.Resize(opt.img_size),transforms.CenterCrop(opt.img_size),transforms.ToTensor(),transforms.Normalize([0.5], [0.5], [0.5])])celebA_dataset = CelebADataset(dataset['train'], transform=transform)dataloader = DataLoader(celebA_dataset, batch_size=opt.batch_size, shuffle=True, num_workers=opt.n_cpu)parser = argparse.ArgumentParser()parser.add_argument("--n_epochs", type=int, default=200, help="number of epochs of training")parser.add_argument("--batch_size", type=int, default=64, help="size of the batches")parser.add_argument("--lr", type=float, default=0.0002, help="adam: learning rate")parser.add_argument("--b1", type=float, default=0.5, help="adam: decay of first order momentum of gradient")parser.add_argument("--b2", type=float, default=0.999, help="adam: decay of first order momentum of gradient")parser.add_argument("--n_cpu", type=int, default=4, help="number of cpu threads to use during batch generation")parser.add_argument("--latent_dim", type=int, default=100, help="dimensionality of the latent space")parser.add_argument("--img_size", type=int, default=128, help="size of each image dimension")parser.add_argument("--channels", type=int, default=3, help="number of image channels")parser.add_argument("--sample_interval", type=int, default=400, help="interval between image sampling")opt = parser.parse_args(args=[])# Loss functionadversarial_loss = torch.nn.BCELoss()def context_loss(output, target):    if output.is_cuda and not target.is_cuda:        target = target.cuda()    elif not output.is_cuda and target.is_cuda:        output = output.cuda()    return nn.MSELoss()(output, target)# Initialize generator and discriminatorgenerator = Generator()discriminator = Discriminator()if cuda:    generator.cuda()    discriminator.cuda()    adversarial_loss.cuda()# Initialize weightsgenerator.apply(weights_init_normal)discriminator.apply(weights_init_normal)optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2),weight_decay = opt.wd)optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2),weight_decay = opt.wd)Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensorwandb.login(key="833b800ff23eb3d26e6c85a8b9e1fc8bbafc9775")wandb.init(project="DCGAN-CelebA", config=opt.__dict__)# Training loopfor epoch in range(opt.n_epochs):    for i,imgs in enumerate(dataloader):        # Adversarial ground truths        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)        # Configure input        real_imgs = Variable(imgs.type(Tensor))                        # Train Generator        optimizer_G.zero_grad()        # Sample noise as generator input        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))        # Generate a batch of images        gen_imgs = generator(z)        # Loss measures generator's ability to fool the discriminator        g_loss = adversarial_loss(discriminator(gen_imgs), valid)+ context_loss(gen_imgs, real_imgs)        g_loss.backward()        optimizer_G.step()        # Train Discriminator        optimizer_D.zero_grad()        # Measure discriminator's ability to classify real from generated samples        real_loss = adversarial_loss(discriminator(real_imgs), valid)        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)        d_loss = (real_loss + fake_loss) / 2        d_loss.backward()        optimizer_D.step()                wandb.log({"G_loss": g_loss.item(), "D_loss": d_loss.item(), "epoch": epoch})                # Every few batches, save and log images        if epoch % 10 == 0:            wandb.log({"generated_images": [wandb.Image(gen_imgs.data[:16], caption=f"Epoch {epoch}")]})            # Log model weights and biases at the end of every epoch            wandb.log({            # Generator Weights and Biases            "Generator Weights (l1.0)": wandb.Histogram(generator.state_dict()['l1.0.weight'].cpu().numpy()),            "Generator Biases (l1.0)": wandb.Histogram(generator.state_dict()['l1.0.bias'].cpu().numpy()),            "Generator Weights (conv_blocks.0)": wandb.Histogram(generator.state_dict()['conv_blocks.0.weight'].cpu().numpy()),            "Generator Biases (conv_blocks.0)": wandb.Histogram(generator.state_dict()['conv_blocks.0.bias'].cpu().numpy()),            # Discriminator Weights and Biases            "Discriminator Weights (model.0)": wandb.Histogram(discriminator.state_dict()['model.0.weight'].cpu().numpy()),            "Discriminator Biases (model.0)": wandb.Histogram(discriminator.state_dict()['model.0.bias'].cpu().numpy()),            "Discriminator Weights (model.3)": wandb.Histogram(discriminator.state_dict()['model.3.weight'].cpu().numpy()),            "Discriminator Biases (model.3)": wandb.Histogram(discriminator.state_dict()['model.3.bias'].cpu().numpy()),})wandb.finish()